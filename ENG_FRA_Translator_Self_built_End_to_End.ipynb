{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yy5W63b8EZ6k"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, GRU, TextVectorization, Dense, Embedding, Input, MultiHeadAttention, LayerNormalization, Layer\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "wR_Z69liSrD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.manythings.org/anki/fra-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzHugv3fFIQ8",
        "outputId": "cab23bb2-0197-43f8-ab1a-a1c9109142c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-30 02:27:32--  https://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7420323 (7.1M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   7.08M  4.15MB/s    in 1.7s    \n",
            "\n",
            "2023-07-30 02:27:35 (4.15 MB/s) - ‘fra-eng.zip’ saved [7420323/7420323]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/fra-eng.zip\" -d \"/content/dataset/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6BFzGTgFvl5",
        "outputId": "fef7e129-7b92-470d-b0da-e0f9ca2001b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/fra-eng.zip\n",
            "  inflating: /content/dataset/_about.txt  \n",
            "  inflating: /content/dataset/fra.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "downloaded_dataset = tf.data.TextLineDataset('/content/dataset/fra.txt')"
      ],
      "metadata": {
        "id": "VTg1_rSZGI6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ll2smPxTH7M5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to separate english text from french text\n",
        "def selector(text_data):\n",
        "  split_text = tf.strings.split(text_data, sep='\\t')\n",
        "  return {'input_1': split_text[0], 'input_2': 'starttoken ' + split_text[1]}, split_text[1] + ' endtoken'"
      ],
      "metadata": {
        "id": "LxOc0Ys1Gfr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to help create english and french vocabulary\n",
        "def separator(text_data):\n",
        "  split_text = tf.strings.split(text_data, sep='\\t')\n",
        "  return split_text[0], 'starttoken ' + split_text[1] + ' endtoken'"
      ],
      "metadata": {
        "id": "mNCWBrBoGk83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_text = downloaded_dataset.map(selector)"
      ],
      "metadata": {
        "id": "9CQTSOEdJfhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in selected_text.take(2):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOwKzBVLJmT8",
        "outputId": "78506235-9cc0-430f-e013-502c352dff9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(), dtype=string, numpy=b'Go.'>, 'input_2': <tf.Tensor: shape=(), dtype=string, numpy=b'starttoken Va !'>}, <tf.Tensor: shape=(), dtype=string, numpy=b'Va ! endtoken'>)\n",
            "({'input_1': <tf.Tensor: shape=(), dtype=string, numpy=b'Go.'>, 'input_2': <tf.Tensor: shape=(), dtype=string, numpy=b'starttoken Marche.'>}, <tf.Tensor: shape=(), dtype=string, numpy=b'Marche. endtoken'>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "separated_text = downloaded_dataset.map(separator)"
      ],
      "metadata": {
        "id": "rOAOcC8hJq_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in separated_text.take(2):\n",
        "\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8wnvaCHL3ah",
        "outputId": "514f7e71-448d-40b1-a228-75ddc843e342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(), dtype=string, numpy=b'Go.'>, <tf.Tensor: shape=(), dtype=string, numpy=b'starttoken Va ! endtoken'>)\n",
            "(<tf.Tensor: shape=(), dtype=string, numpy=b'Go.'>, <tf.Tensor: shape=(), dtype=string, numpy=b'starttoken Marche. endtoken'>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#How about we adapt a vectorizer on the separated text to get english and french vocabulary\n",
        "\n",
        "#Firstly define global variables\n",
        "\n",
        "VOCAB_SIZE = 20000\n",
        "ENGLISH_SEQUENCE_LENGTH = 64\n",
        "FRENCH_SEQUENCE_LENGTH = 64\n",
        "EMBEDDING_DIM = 512\n",
        "BATCH_SIZE = 64\n",
        "HIDDEN_UNITS = 256"
      ],
      "metadata": {
        "id": "0AnqkNpxL-y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_vectorize_layer = TextVectorization(\n",
        "    standardize = 'lower_and_strip_punctuation',\n",
        "    max_tokens = VOCAB_SIZE,\n",
        "    output_mode = 'int',\n",
        "    output_sequence_length = ENGLISH_SEQUENCE_LENGTH\n",
        ")"
      ],
      "metadata": {
        "id": "s-Cp8_f6Nxbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "french_vectorize_layer = TextVectorization(\n",
        "    standardize = 'lower_and_strip_punctuation',\n",
        "    max_tokens = VOCAB_SIZE,\n",
        "    output_mode = 'int',\n",
        "    output_sequence_length = FRENCH_SEQUENCE_LENGTH\n",
        ")"
      ],
      "metadata": {
        "id": "qLqoIpvNOZzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english = separated_text.map(lambda x,y:x)\n",
        "english_vectorize_layer.adapt(english)"
      ],
      "metadata": {
        "id": "vRtMgRAnOjMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "french = separated_text.map(lambda x,y:y)\n",
        "french_vectorize_layer.adapt(french)"
      ],
      "metadata": {
        "id": "Po4aWFkfOxoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize(input, output):\n",
        "  return {\n",
        "     'input_1' : english_vectorize_layer(input['input_1']),\n",
        "     'input_2' : french_vectorize_layer(input['input_2'])\n",
        "  }, french_vectorize_layer(output)"
      ],
      "metadata": {
        "id": "-b3a5SNHO-dN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = selected_text.map(vectorize)"
      ],
      "metadata": {
        "id": "QfwV87rpRFih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in dataset.take(5):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gGmd5GaRRgF",
        "outputId": "be24b42d-e503-41ac-ae1b-fe957e3379b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
            "array([44,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])>, 'input_2': <tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
            "array([  2, 104,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])>}, <tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
            "array([104,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])>)\n",
            "({'input_1': <tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
            "array([44,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])>, 'input_2': <tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
            "array([  2, 821,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])>}, <tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
            "array([821,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])>)\n",
            "({'input_1': <tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
            "array([44,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])>, 'input_2': <tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
            "array([  2,  23, 611,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])>}, <tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
            "array([ 23, 611,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])>)\n",
            "({'input_1': <tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
            "array([44,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])>, 'input_2': <tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
            "array([   2, 2727,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0])>}, <tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
            "array([2727,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0])>)\n",
            "({'input_1': <tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
            "array([2534,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0])>, 'input_2': <tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
            "array([   2, 3470,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0])>}, <tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
            "array([3470,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0])>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.shuffle(2048).unbatch().batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "2IQLzipxRdg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxpxa9aEVidt",
        "outputId": "6e584d9d-de60-480f-92a4-38b45d1bb081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=({'input_1': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None,), dtype=tf.int64, name=None)}, TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_batches = 200000 / BATCH_SIZE\n",
        "\n",
        "train_data = dataset.take(int(0.9*num_batches))\n",
        "test_data = dataset.skip(int(0.9*num_batches))"
      ],
      "metadata": {
        "id": "goggl0GHVkQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, the most crucial part is to build an encoder-decoder architecture with bahdanau's attention mechanism\n",
        "\n",
        "# The encoder block\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, lstm_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.lstm_units = lstm_units\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.embedding = Embedding(self.vocab_size, self.embedding_dim)\n",
        "    self.bidirectional_lstm = Bidirectional(LSTM(self.lstm_units, return_sequences=True))\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.embedding(x)\n",
        "    output = self.bidirectional_lstm(x)\n",
        "\n",
        "    return output\n",
        "\n"
      ],
      "metadata": {
        "id": "MGEBDASPWSOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create customized bahdanau attention class to be used as layer in the decoder block\n",
        "\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.dense1 = Dense(self.units)\n",
        "    self.dense2 = Dense(self.units)\n",
        "    self.dense = Dense(1)\n",
        "\n",
        "  def call(self, previous_decoder_state, encoder_output):\n",
        "    scores = self.dense(\n",
        "                  tf.nn.tanh(\n",
        "                        self.dense1(tf.expand_dims(previous_decoder_state, axis=-2)) +\n",
        "                        self.dense2(encoder_output)\n",
        "\n",
        "                            )\n",
        "    )\n",
        "\n",
        "    attention_weights = tf.nn.softmax(scores, axis=1)\n",
        "    context_vector = attention_weights * encoder_output\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector"
      ],
      "metadata": {
        "id": "eircpTrFaOhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We now create the decoder block\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim, sequence_length, hidden_units):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.sequence_length = sequence_length\n",
        "    self.hidden_units = hidden_units\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.embedding = Embedding(self.vocab_size, self.embedding_dim)\n",
        "    self.attention = BahdanauAttention(self.hidden_units)\n",
        "    self.gru = GRU(self.hidden_units, return_sequences=True, return_state=True)\n",
        "    self.dense = Dense(self.vocab_size, activation='softmax')\n",
        "\n",
        "  def call(self, x, previous_decoder_hidden_state, shifted_targets):\n",
        "    outputs = []\n",
        "    shifted_targets = self.embedding(shifted_targets)\n",
        "\n",
        "    for time_step in range(self.sequence_length):\n",
        "      context_vector = self.attention(previous_decoder_hidden_state, x)\n",
        "\n",
        "      decoder_input = context_vector + shifted_targets[:, time_step]\n",
        "\n",
        "      output, hidden_state = self.gru(tf.expand_dims(decoder_input, axis=1))\n",
        "\n",
        "      outputs.append(output[:,0])\n",
        "\n",
        "    final_output = tf.convert_to_tensor(outputs)\n",
        "    final_output  = tf.transpose(final_output, perm=[1,0,2])\n",
        "\n",
        "    final_output = self.dense(final_output)\n",
        "\n",
        "    return final_output\n",
        "\n"
      ],
      "metadata": {
        "id": "8pYC_OKZdyEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define parameters for model\n",
        "\n",
        "#Encoder\n",
        "input = Input(shape=(ENGLISH_SEQUENCE_LENGTH,), dtype='int64', name='input_1')\n",
        "encoder = Encoder(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_UNITS)\n",
        "\n",
        "encoder_output = encoder(input)\n",
        "\n",
        "#Decoder\n",
        "shifted_targets = Input(shape=(FRENCH_SEQUENCE_LENGTH,), dtype='int64', name='input_2')\n",
        "\n",
        "decoder = Decoder(VOCAB_SIZE, EMBEDDING_DIM, FRENCH_SEQUENCE_LENGTH, HIDDEN_UNITS)\n",
        "\n",
        "output = decoder(encoder_output, tf.zeros([1, HIDDEN_UNITS]), shifted_targets)\n",
        "\n",
        "\n",
        "#Model\n",
        "trans_model = Model([input, shifted_targets], output)\n",
        "trans_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj7r9ayXfCs0",
        "outputId": "610065aa-18ba-499c-d434-76b43f1d400d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " encoder (Encoder)              (None, 64, 512)      11814912    ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " decoder (Decoder)              (None, 64, 20000)    16168737    ['encoder[0][0]',                \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 27,983,649\n",
            "Trainable params: 27,983,649\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function (method) that handles the positional encoding\n",
        "\n",
        "def positional_encoding(d_model, sequence_length):\n",
        "\n",
        "    \"\"\"\n",
        "    Computes the positional encoding that will be added to input embedding vectors\n",
        "\n",
        "    Args\n",
        "\n",
        "    -----\n",
        "\n",
        "    d_model --> dtype - int\n",
        "    sequence_length --> dtype - int\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    output = []\n",
        "\n",
        "    for pos in range(sequence_length):\n",
        "\n",
        "        #Initialize the positional encoding with zeros\n",
        "        PE = np.zeros((d_model))\n",
        "\n",
        "        for i in range(d_model):\n",
        "\n",
        "            if i%2==0:\n",
        "                PE[i] = np.sin(pos / (10000**((i) / d_model)))\n",
        "\n",
        "            else:\n",
        "                PE[i] = np.cos(pos / (10000**((i-1) / d_model)))\n",
        "\n",
        "        output.append(tf.expand_dims(PE, axis=0))\n",
        "\n",
        "    out = tf.concat(output, axis=0)\n",
        "    out  = tf.expand_dims(out, axis=0)\n",
        "\n",
        "    return tf.cast(out, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "xphwaKHIfEmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Embedding Layer\n",
        "\n",
        "class Embeddings(Layer):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, sequence_length):\n",
        "\n",
        "        super(Embeddings, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.sequence_length = sequence_length\n",
        "\n",
        "        self.embedding_layer = Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        embedded_tokens = self.embedding_layer(inputs)\n",
        "        position_encoding = positional_encoding(self.embedding_dim, self.sequence_length)\n",
        "\n",
        "        final_embedding = position_encoding + embedded_tokens\n",
        "\n",
        "        return final_embedding\n",
        "\n",
        "    def mask(self, inputs, mask=None):\n",
        "\n",
        "        mask = tf.math.not_equal(inputs, 0)\n",
        "\n",
        "\n",
        "\n",
        "        return mask\n"
      ],
      "metadata": {
        "id": "yAy1cBP1fokc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(Layer):\n",
        "\n",
        "    def __init__(self, embedd_dim, dense_dim, num_heads):\n",
        "\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "\n",
        "        self.embedd_dim = embedd_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.multi_head_attention = MultiHeadAttention(num_heads=self.num_heads, key_dim=self.embedd_dim)\n",
        "        self.feed_forward = tf.keras.Sequential([Dense(self.dense_dim, activation='relu'), Dense(self.embedd_dim)])\n",
        "        self.layer_norm_1 = LayerNormalization()\n",
        "        self.layer_norm_2 = LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "\n",
        "        padding_mask = None\n",
        "\n",
        "        if mask is not None:\n",
        "            mask_1 = mask[:, :, tf.newaxis]\n",
        "            mask_2 = mask[:, tf.newaxis, :]\n",
        "            padding_mask = tf.cast(mask_1&mask_2, dtype=tf.int32)\n",
        "\n",
        "\n",
        "        output_1 = self.multi_head_attention(query=inputs, key=inputs, value=inputs, attention_mask=padding_mask)\n",
        "\n",
        "        projection = self.layer_norm_1(inputs + output_1)\n",
        "        feed_forward_output = self.feed_forward(projection)\n",
        "\n",
        "        final_output = self.layer_norm_2(projection + feed_forward_output)\n",
        "\n",
        "        return final_output"
      ],
      "metadata": {
        "id": "1a7iI43XfrSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(Layer):\n",
        "\n",
        "    def __init__(self, embedd_dim, dense_dim, num_heads):\n",
        "\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "\n",
        "        self.embedd_dim  = embedd_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.multi_head_attention_1 = MultiHeadAttention(num_heads=self.num_heads, key_dim=self.embedd_dim)\n",
        "        self.multi_head_attention_2 = MultiHeadAttention(num_heads=self.num_heads, key_dim=self.embedd_dim)\n",
        "        self.feed_forward = tf.keras.Sequential([Dense(self.dense_dim, activation='relu'), Dense(self.embedd_dim)])\n",
        "        self.layer_norm_1 = LayerNormalization()\n",
        "        self.layer_norm_2 = LayerNormalization()\n",
        "        self.layer_norm_3 = LayerNormalization()\n",
        "        self.encoder = TransformerEncoder(self.embedd_dim, self.dense_dim, self.num_heads)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "\n",
        "        padding_mask = None\n",
        "\n",
        "        if mask is not None:\n",
        "            mask_1 = mask[:, :, tf.newaxis]\n",
        "            mask_2 = mask[:, tf.newaxis, :]\n",
        "            padding_mask = tf.cast(mask_1&mask_2, dtype=tf.int32)\n",
        "\n",
        "\n",
        "        attention_output_1 = self.multi_head_attention_1(query=inputs, key=inputs, value=inputs, attention_mask=padding_mask,\n",
        "                                                       use_causal_mask=True)\n",
        "\n",
        "        query_input = self.layer_norm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.multi_head_attention_2(query=query_input, key=encoder_outputs,\n",
        "                                                         value=encoder_outputs, attention_mask=padding_mask)\n",
        "        feed_forward_input = self.layer_norm_2(query_input + attention_output_2)\n",
        "\n",
        "        feed_forward_output = self.feed_forward(feed_forward_input)\n",
        "\n",
        "        final_output = self.layer_norm_3(feed_forward_input + feed_forward_output)\n",
        "\n",
        "        return final_output"
      ],
      "metadata": {
        "id": "s29_JFWRfxgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM=128\n",
        "D_FF=1024\n",
        "NUM_HEADS=8\n",
        "NUM_LAYERS=4\n",
        "NUM_EPOCHS=20\n"
      ],
      "metadata": {
        "id": "-eHdg21AA4Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs=Input(shape=(None,), dtype=\"int64\", name=\"input_1\")\n",
        "x = Embeddings(VOCAB_SIZE, EMBEDDING_DIM, ENGLISH_SEQUENCE_LENGTH)(encoder_inputs)\n",
        "\n",
        "for _ in range(NUM_LAYERS):\n",
        " encoder_output=TransformerEncoder(EMBEDDING_DIM,D_FF,NUM_HEADS)(x)\n",
        "encoder_outputs = encoder_output\n",
        "\n",
        "print(encoder_outputs.shape)\n",
        "\n",
        "\n",
        "decoder_inputs=Input(shape=(None,), dtype=\"int64\", name=\"input_2\")\n",
        "\n",
        "x = Embeddings(VOCAB_SIZE, EMBEDDING_DIM, FRENCH_SEQUENCE_LENGTH)(decoder_inputs)\n",
        "for i in range(NUM_LAYERS):\n",
        "  x=TransformerDecoder(EMBEDDING_DIM,D_FF,NUM_HEADS)(x, encoder_outputs)\n",
        "\n",
        "\n",
        "decoder_outputs=Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
        "\n",
        "transformer = tf.keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")\n",
        "transformer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8u2LFuBBE75",
        "outputId": "8cc2c992-9da7-4db4-c2ab-643c86d571e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 64, 128)\n",
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embeddings (Embeddings)        (None, 64, 128)      2560000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embeddings_1 (Embeddings)      (None, 64, 128)      2560000     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " transformer_encoder_3 (Transfo  (None, 64, 128)     791296      ['embeddings[0][0]']             \n",
            " rmerEncoder)                                                                                     \n",
            "                                                                                                  \n",
            " transformer_decoder (Transform  (None, 64, 128)     1319040     ['embeddings_1[0][0]',           \n",
            " erDecoder)                                                       'transformer_encoder_3[0][0]']  \n",
            "                                                                                                  \n",
            " transformer_decoder_1 (Transfo  (None, 64, 128)     1319040     ['transformer_decoder[0][0]',    \n",
            " rmerDecoder)                                                     'transformer_encoder_3[0][0]']  \n",
            "                                                                                                  \n",
            " transformer_decoder_2 (Transfo  (None, 64, 128)     1319040     ['transformer_decoder_1[0][0]',  \n",
            " rmerDecoder)                                                     'transformer_encoder_3[0][0]']  \n",
            "                                                                                                  \n",
            " transformer_decoder_3 (Transfo  (None, 64, 128)     1319040     ['transformer_decoder_2[0][0]',  \n",
            " rmerDecoder)                                                     'transformer_encoder_3[0][0]']  \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64, 20000)    2580000     ['transformer_decoder_3[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13,767,456\n",
            "Trainable params: 13,767,456\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BLEU(tf.keras.metrics.Metric):\n",
        "    def __init__(self,name='bleu_score'):\n",
        "        super(BLEU,self).__init__()\n",
        "        self.bleu_score=0\n",
        "\n",
        "    def update_state(self,y_true,y_pred,sample_weight=None):\n",
        "      y_pred=tf.argmax(y_pred,-1)\n",
        "      self.bleu_score=0\n",
        "      for i,j in zip(y_pred,y_true):\n",
        "        tf.autograph.experimental.set_loop_options()\n",
        "\n",
        "        total_words=tf.math.count_nonzero(i)\n",
        "        total_matches=0\n",
        "        for word in i:\n",
        "          if word==0:\n",
        "            break\n",
        "          for q in range(len(j)):\n",
        "            if j[q]==0:\n",
        "              break\n",
        "            if word==j[q]:\n",
        "              total_matches+=1\n",
        "              j=tf.boolean_mask(j,[False if y==q else True for y in range(len(j))])\n",
        "              break\n",
        "\n",
        "        self.bleu_score+=total_matches/total_words\n",
        "\n",
        "    def result(self):\n",
        "        return self.bleu_score/BATCH_SIZE"
      ],
      "metadata": {
        "id": "eMumCFjoJwMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(2e-4),) #metrics=[BLEU()],\n",
        "    #run_eagerly=True)"
      ],
      "metadata": {
        "id": "UAm4YcNWJ3Vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=transformer.fit(\n",
        "    train_data,\n",
        "    validation_data=test_data.take(300),\n",
        "    epochs=NUM_EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_uecU2QJ8rt",
        "outputId": "b45168d8-8a35-4378-d243-fd8892ff4991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2812/2812 [==============================] - 102s 27ms/step - loss: 0.5889 - val_loss: 0.2968\n",
            "Epoch 2/20\n",
            "2812/2812 [==============================] - 70s 25ms/step - loss: 0.2506 - val_loss: 0.2674\n",
            "Epoch 3/20\n",
            "2812/2812 [==============================] - 70s 25ms/step - loss: 0.2381 - val_loss: 0.2470\n",
            "Epoch 4/20\n",
            "2812/2812 [==============================] - 71s 25ms/step - loss: 0.2273 - val_loss: 0.2615\n",
            "Epoch 5/20\n",
            "2812/2812 [==============================] - 72s 25ms/step - loss: 0.2259 - val_loss: 0.2515\n",
            "Epoch 6/20\n",
            "2812/2812 [==============================] - 73s 26ms/step - loss: 0.2220 - val_loss: 0.2495\n",
            "Epoch 7/20\n",
            "2812/2812 [==============================] - 71s 25ms/step - loss: 0.2177 - val_loss: 0.2508\n",
            "Epoch 8/20\n",
            "2812/2812 [==============================] - 70s 25ms/step - loss: 0.2159 - val_loss: 0.2581\n",
            "Epoch 9/20\n",
            "2812/2812 [==============================] - 70s 25ms/step - loss: 0.2229 - val_loss: 0.2812\n",
            "Epoch 10/20\n",
            "2812/2812 [==============================] - 72s 25ms/step - loss: 0.2348 - val_loss: 0.2524\n",
            "Epoch 11/20\n",
            "2812/2812 [==============================] - 70s 25ms/step - loss: 0.2343 - val_loss: 0.2558\n",
            "Epoch 12/20\n",
            "2812/2812 [==============================] - 71s 25ms/step - loss: 0.2214 - val_loss: 0.2547\n",
            "Epoch 13/20\n",
            "2812/2812 [==============================] - 70s 25ms/step - loss: 0.2130 - val_loss: 0.2497\n",
            "Epoch 14/20\n",
            "2812/2812 [==============================] - 70s 24ms/step - loss: 0.2083 - val_loss: 0.2464\n",
            "Epoch 15/20\n",
            "2812/2812 [==============================] - 71s 25ms/step - loss: 0.2086 - val_loss: 0.2440\n",
            "Epoch 16/20\n",
            "2812/2812 [==============================] - 71s 25ms/step - loss: 0.2081 - val_loss: 0.2469\n",
            "Epoch 17/20\n",
            "2812/2812 [==============================] - 70s 25ms/step - loss: 0.2000 - val_loss: 0.2298\n",
            "Epoch 18/20\n",
            "2812/2812 [==============================] - 69s 24ms/step - loss: 0.1909 - val_loss: 0.2323\n",
            "Epoch 19/20\n",
            "2812/2812 [==============================] - 69s 24ms/step - loss: 0.1858 - val_loss: 0.2241\n",
            "Epoch 20/20\n",
            "2812/2812 [==============================] - 70s 25ms/step - loss: 0.1809 - val_loss: 0.2210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transformer.evaluate(test_data)"
      ],
      "metadata": {
        "id": "E-0k2prQKDqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word={x:y for x, y in zip(range(len(french_vectorize_layer.get_vocabulary())),\n",
        "                                   french_vectorize_layer.get_vocabulary())}"
      ],
      "metadata": {
        "id": "LuwlaA77Mnr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translator(english_sentence):\n",
        "  tokenized_english_sentence=english_vectorize_layer([english_sentence])\n",
        "  shifted_target='starttoken'\n",
        "\n",
        "  for i in range(FRENCH_SEQUENCE_LENGTH):\n",
        "    tokenized_shifted_target=french_vectorize_layer([shifted_target])\n",
        "    output=transformer.predict([tokenized_english_sentence,tokenized_shifted_target], verbose=0)\n",
        "    french_word_index=tf.argmax(output,axis=-1)[0][i].numpy()\n",
        "    current_word=index_to_word[french_word_index]\n",
        "    if current_word=='endtoken':\n",
        "      break\n",
        "    shifted_target+=' '+current_word\n",
        "  return shifted_target[11:]"
      ],
      "metadata": {
        "id": "gnnG1ukPNa-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator('What makes you think that it is not true?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Y1NADEHcNeOv",
        "outputId": "afe35356-78fd-46dd-b5fa-44e85fd7fb28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cest que tom'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator('Have you ever watched soccer under the rain?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VWWOnOL3NiVf",
        "outputId": "94b0900d-a628-403f-e551-adbb702af3b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[UNK]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator(\"what's your name?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SDvrXtWGN9a6",
        "outputId": "494388ec-38b0-4e09-e695-ff6dc1ebd49a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[UNK]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator('She handed him the money')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7TW_l1_-huuW",
        "outputId": "55d38889-bccb-4a9c-d37c-20643e0c0b3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cest que tom'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(model_size,SEQUENCE_LENGTH):\n",
        "  output=[]\n",
        "  for pos in range(SEQUENCE_LENGTH):\n",
        "    PE=np.zeros((model_size))\n",
        "    for i in range(model_size):\n",
        "      if i%2==0:\n",
        "        PE[i]=np.sin(pos/(10000**(i/model_size)))\n",
        "      else:\n",
        "        PE[i]=np.cos(pos/(10000**((i-1)/model_size)))\n",
        "    output.append(tf.expand_dims(PE,axis=0))\n",
        "  out=tf.concat(output,axis=0)\n",
        "  out=tf.expand_dims(out,axis=0)\n",
        "  return tf.cast(out,dtype=tf.float32)"
      ],
      "metadata": {
        "id": "WAtk2zBgyNY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(Layer):\n",
        "  def __init__(self, sequence_length, vocab_size, embed_dim,):\n",
        "    super(Embeddings, self).__init__()\n",
        "    self.token_embeddings=Embedding(\n",
        "        input_dim=vocab_size, output_dim=embed_dim)\n",
        "    self.sequence_length = sequence_length\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embed_dim = embed_dim\n",
        "\n",
        "  def call(self, inputs):\n",
        "    embedded_tokens = self.token_embeddings(inputs)\n",
        "    embedded_positions=positional_encoding(\n",
        "        self.embed_dim,self.sequence_length)\n",
        "    return embedded_tokens + embedded_positions\n",
        "\n",
        "  def compute_mask(self, inputs, mask=None):\n",
        "    return tf.math.not_equal(inputs, 0)"
      ],
      "metadata": {
        "id": "dad0iU6RyVr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads,):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim,\n",
        "        )\n",
        "        self.dense_proj=tf.keras.Sequential(\n",
        "            [Dense(dense_dim, activation=\"relu\"),Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = LayerNormalization()\n",
        "        self.layernorm_2 = LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "\n",
        "      padding_mask = None\n",
        "      if mask is not None:\n",
        "        mask1 = mask[:, :, tf.newaxis]\n",
        "        mask2 = mask[:,tf.newaxis, :]\n",
        "        padding_mask = tf.cast(mask1&mask2, dtype=\"int32\")\n",
        "\n",
        "      attention_output = self.attention(\n",
        "          query=inputs, key=inputs,value=inputs,attention_mask=padding_mask\n",
        "      )\n",
        "\n",
        "      proj_input = self.layernorm_1(inputs + attention_output)\n",
        "      proj_output = self.dense_proj(proj_input)\n",
        "      return self.layernorm_2(proj_input + proj_output)"
      ],
      "metadata": {
        "id": "gDGI9fwDh3rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(Layer):\n",
        "  def __init__(self, embed_dim, latent_dim, num_heads,):\n",
        "    super(TransformerDecoder, self).__init__()\n",
        "    self.embed_dim = embed_dim\n",
        "    self.latent_dim = latent_dim\n",
        "    self.num_heads = num_heads\n",
        "    self.attention_1=MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=embed_dim\n",
        "    )\n",
        "    self.attention_2=MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=embed_dim\n",
        "    )\n",
        "    self.dense_proj = tf.keras.Sequential(\n",
        "        [Dense(latent_dim, activation=\"relu\"),Dense(embed_dim),]\n",
        "    )\n",
        "    self.layernorm_1=LayerNormalization()\n",
        "    self.layernorm_2=LayerNormalization()\n",
        "    self.layernorm_3=LayerNormalization()\n",
        "    self.supports_masking = True\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, inputs, encoder_outputs, mask=None):\n",
        "\n",
        "    if mask is not None:\n",
        "      padding_mask = None\n",
        "      mask1 = mask[:, :, tf.newaxis]\n",
        "      mask2 = mask[:,tf.newaxis, :]\n",
        "      padding_mask = tf.cast(mask1&mask2, dtype=\"int32\")\n",
        "      causal_mask=tf.linalg.band_part(tf.ones([tf.shape(inputs)[0],tf.shape(inputs)[1],\n",
        "                                               tf.shape(inputs)[1]],dtype=tf.int32),-1,0)\n",
        "      combined_mask=tf.minimum(padding_mask,causal_mask)\n",
        "\n",
        "    attention_output_1 = self.attention_1(\n",
        "        query=inputs,key=inputs,value=inputs,\n",
        "        attention_mask=causal_mask,\n",
        "\n",
        "    )\n",
        "    out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "    attention_output_2,scores= self.attention_2(\n",
        "        query=out_1,key=encoder_outputs,value=encoder_outputs,\n",
        "        attention_mask=combined_mask,\n",
        "    )\n",
        "    out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "    proj_output = self.dense_proj(out_2)\n",
        "    return self.layernorm_3(out_2 + proj_output)"
      ],
      "metadata": {
        "id": "Qt6i0Vp9jCJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs=Input(shape=(None,), dtype=\"int64\", name=\"input_1\")\n",
        "x = Embeddings(ENGLISH_SEQUENCE_LENGTH,VOCAB_SIZE,EMBEDDING_DIM)(encoder_inputs)\n",
        "\n",
        "for _ in range(NUM_LAYERS):\n",
        "  encoder=TransformerEncoder(EMBEDDING_DIM,D_FF,NUM_HEADS)(x)\n",
        "encoder_outputs=encoder\n",
        "\n",
        "decoder_inputs=Input(shape=(None,), dtype=\"int64\", name=\"input_2\")\n",
        "\n",
        "x = Embeddings(FRENCH_SEQUENCE_LENGTH,VOCAB_SIZE,EMBEDDING_DIM)(decoder_inputs)\n",
        "for i in range(NUM_LAYERS):\n",
        "  x=TransformerDecoder(EMBEDDING_DIM,D_FF,NUM_HEADS)(x, encoder_outputs)\n",
        "decoder_outputs=Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
        "\n",
        "transformer = tf.keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")\n",
        "transformer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "n758QocwjGbM",
        "outputId": "d6e70f7c-443a-4b2c-f06e-4c2ed90f22e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OperatorNotAllowedInGraphError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-0956a7ba883e>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFRENCH_SEQUENCE_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_LAYERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTransformerDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD_FF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNUM_HEADS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1198\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: Exception encountered when calling layer \"transformer_decoder_10\" (type TransformerDecoder).\n\nin user code:\n\n    File \"<ipython-input-52-965e1d60e220>\", line 40, in call  *\n        attention_output_2,scores= self.attention_2(\n\n    OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n\n\nCall arguments received by layer \"transformer_decoder_10\" (type TransformerDecoder):\n  • inputs=tf.Tensor(shape=(None, 64, 128), dtype=float32)\n  • encoder_outputs=tf.Tensor(shape=(None, 64, 128), dtype=float32)\n  • mask=tf.Tensor(shape=(None, None), dtype=bool)"
          ]
        }
      ]
    }
  ]
}